% ncse_new/p1_SystemsOfEquations/ch3_IterativeMethodsNonLinear/ex_QuadraticConvergence.tex
% ex_OrderConv.m


\begin{problem}[The order of convergence of an iterative scheme \coreproblem] \label{prb:QuadraticConvergence}
%  \ncseref[Lemma]{lem:fpcvg} gives a criterion for higher order local convergence of a fixed point iteration $x=\Phi(x)$ in 1D.

\lref{rem:eoc} shows how to detect the order of convergence of an iterative method
from a numerical experiment. In this problem we study the so-called
\href{http://en.wikipedia.org/wiki/Steffensen's_method}{Steffensen's method},
which is a derivative-free iterative method for finding zeros of functions in 1D.

Let $f:[a,b]\mapsto\bbR$ be twice continuously differentiable with $f(x^{\ast})=0$ and $f'(x^{\ast})\not=0$.
Consider the iteration defined by
$$ x^{(n+1)}=x^{(n)}-\frac{f(x^{(n)})}{g(x^{(n)})},\quad \text{where}\quad g(x)=\frac{f(x+f(x))-f(x)}{f(x)}.$$

\begin{subproblem}[2]
Write a \Matlab{} script that computes the order of convergence to the point $x^*$ of this iteration for the function $f(x)=xe^x-1$ (see \ncseex{ex:fixp}). Use $x^{(0)} = 1$.

\cprotEnv \begin{solution}
\lstinputlisting[caption={Order of convergence}, label={mc:ex_OrderConv}, escapechar={}]
{\problems/\chpt/MATLAB/ex_OrderConv.m}

The output is\\
\begin{center}
\begin{tabular}{lll}
   $x$   &          error $e_n$   &   $\frac{\log(e_{n+1})-\log(e_n)}{\log(e_{n})-\log(e_n-1)}$ \\
   \hline
   $1.000000000000000 $ & $  0.432856709590216  $ &                    \\
   $0.923262600967822 $ & $  0.356119310558038  $ &                   \\
   $0.830705934728425 $ & $  0.263562644318641  $ & $    1.542345498206531$\\
   $0.727518499997190 $ & $  0.160375209587406  $ & $    1.650553641703975$\\
   $0.633710518522047 $ & $  0.066567228112263  $ & $    1.770024323911885$\\
   $0.579846053882820 $ & $  0.012702763473036  $ & $    1.883754995643305$\\
   $0.567633791946526 $ & $  0.000490501536742  $ & $    {\red1.964598248590593}$\\
   $0.567144031581974 $ & $  0.000000741172191  $ & $    {\red1.995899954235929}$\\
   $0.567143290411477 $ & $  0.000000000001693  $ & $    {\red1.999927865685712}$\\
   $0.567143290409784 $ & $  0.000000000000000  $ & $    0.741551601040667$
\end{tabular}
\end{center}

The convergence is obviously quadratic. As in the experiments shown in class,
roundoff affects the estimated order, once the iteration error approaches the
machine precision. 
\end{solution}
\end{subproblem}

\begin{subproblem}[2]
The function $g(x)$ contains a term like $e^{xe^x}$, thus it grows very fast in $x$ and the method can not be started for a large $x^{(0)}$.
How can you modify the function $f$ (keeping the same zero) in order to allow the choice of a larger initial guess?

\begin{hint}
 If $f$ is a function and $h: [a,b] \rightarrow \IR$ with $h(x) \neq 0, \forall x \in [a,b]$, then $(fh)(x) = 0 \Leftrightarrow f(x) = 0$.
\end{hint}


\cprotEnv \begin{solution}
The choice $\tilde f(x) = e^{-x}f(x)= x-e^{-x}$ prevents the blow up of the function $g$ and allows to use a larger set of positive initial points.
Of course, $\tilde f(x)=0$ exactly when $f(x)=0$.

\end{solution}
\end{subproblem}
\end{problem}

% 2009:  proof of 2nd order with Taylor, messy
%
%   Show that this iteration is locally quadratically convergent to $x^{\ast}$.
%
% \verbdef\QuadConvVa{f    := x -> (x-xs)*h(x);}
% \verbdef\QuadConvVb{g    := x -> ( f(x+f(x))-f(x) ) / f(x);}
% \verbdef\QuadConvVc{Phi  := x -> x-f(x)/g(x);}
% \verbdef\QuadConvVd{dPhi := D(Phi)(x);}
% \verbdef\QuadConvVe{limit(%,x=xs);}
% \solution{
% This exercise can be treated in two different ways. Either one uses the indicated lemma or one accomplishes a Taylor expansion to estimate the error expansion.
% Both ways are rather write intensive.
% Therefore the first approach is worked out using the formula manipulation program MAPLE:
% \begin{enumerate}
% \item   We define the function $$\Phi(x)=x -\frac{f(x)}{g(x)} $$
% To show that the fixed point iteration converges quadratically it must hold: $\frac{\partial \Phi(x)}{\partial x}\big\vert_{x=x^*}=0$.
% In MAPLE we write:\\
% \QuadConvVa\\
% \QuadConvVb\\
% \QuadConvVc\\
% \QuadConvVd\\
% \QuadConvVe\\
% The result is essentially $0$. Thus the given method converges quadratically.
% \bigskip
%
% \item
%   $e^{(n)}=x^{(n)}-x^{*}$ is the error of $n^{th}$ iteration by the iteration formula.
%   Supposing $f(x)$ is smooth enough we can use Taylor expansion to express $f(x)$ and
%   $f(x+f(x))$ at $x^{(*)}$ respectively (notice that $f(x^{(*)})=0$):
%   \begin{eqnarray*}
%   f(x^{(n)})&=&f'(x^{(*)})e^{(n)}+f''(x^{*})(e^{(n)})^{2}+O((e^{(n)})^3)\\
%   f(x^{(n)}+f(x^{(n)}))&=&f'(x^{(*)})(1+f'(x^{(*)}))e^{(n)}\\
%   &&+[f''(x^{*})(1+f'(x^{*}))^2+f'(x^{*})f''(x^{*})](e^{(n)})^{2}+O((e^{(n)})^3)
%   \end{eqnarray*}
%   Then
%   \begin{eqnarray*}
%   e^{(n+1)}&=&x^{(n+1)}-x^{*}\\
%   &=&x^{(n)}-x^{*}-\frac{f(x^{(n)})}{g(x^{(n)})}\\
%   &=&e^{(n)}-\frac{f(x^{(n)})}{g(x^{(n)})}\\
% &=&\frac{[f(x^{(n)}+f(x^{(n)}))-f(x^{(n)})]e^{(n)}-f^2(x^{(n)})}{f(x^{(n)}+f(x^{(n)}))-f(x^{(n)})}\\
% &=&\frac{[(f'(x^{*})^{2}f''(x^{*})+f'(x^{*})f''(x^{*})](e^{(n)})^3+O((e^{(n)})^4)}
% {(f'(x^{*}))^2e^{(n)}+O((e^{(n)})^2)}\\
% &\approx & C(e^{(n)})^{2}
%  \end{eqnarray*}
% where $ C=\frac{f''(x^{*})+f'(x^{*})f''(x^{*})}{f'(x^{*})}$.
% So if $f(x)$ belongs to $C^{2}(\mathbb{R})$ and $x^{*}$ is a simple zero of $f(x)$, then the iteration is locally quadratically convergent.
% \end{enumerate}
% }
%
